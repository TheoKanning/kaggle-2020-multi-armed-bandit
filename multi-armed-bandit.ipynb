{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santa 2020 - The Candy Cane Contest\n",
    "\n",
    "Bayesian UCB agent inspired by https://lilianweng.github.io/lil-log/2018/01/23/the-multi-armed-bandit-problem-and-its-solutions.html  \n",
    "Thompson Sampling agent inspired by https://www.kaggle.com/ilialar/simple-multi-armed-bandit  \n",
    "Training data collection inspired by https://www.kaggle.com/lebroschar/1000-greedy-decision-tree-model  \n",
    "Ray support from https://www.kaggle.com/nigelcarpenter/parallel-processing-agent-trials-using-ray  \n",
    "Pull Vegas agent, I never submitted this since it's not my work, but it was useful to train against https://www.kaggle.com/a763337092/pull-vegas-slot-machines-add-weaken-rate-continue5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import ray\n",
    "\n",
    "# my helper files\n",
    "import simulator\n",
    "import stats\n",
    "\n",
    "# agents\n",
    "from agents.classifier import ClassifierAgent\n",
    "from agents.ensemble import EnsembleAgent\n",
    "from agents.keras import KerasAgent\n",
    "from agents.pull_vegas import PullVegasAgent\n",
    "from agents.random import RandomAgent\n",
    "from agents.sklearn import SklearnAgent\n",
    "from agents.thompson import ThompsonAgent\n",
    "from agents.ucb import UcbAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "print(f\"Initializing ray with {num_cpus} cpus\")\n",
    "ray.shutdown()\n",
    "ray.init(num_cpus=num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.smoke_test(ClassifierAgent(100, filename='rl_models/latest.h5'))\n",
    "simulator.smoke_test(KerasAgent(100, filename='keras_models/l3_u8_relu.h5'))\n",
    "simulator.smoke_test(SklearnAgent(100, filename='scikit_models/dtr.joblib'))\n",
    "simulator.smoke_test(EnsembleAgent(100, keras_file='keras_models/l3_u8_relu.h5', scikit_file='scikit_models/dtr.joblib'))\n",
    "simulator.smoke_test(RandomAgent())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "\n",
    "def submit_model(agent_file, model_file, sub_name, message):\n",
    "    if not os.path.exists(agent_file):\n",
    "        print(\"Agent file not found\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(model_file):\n",
    "        print(\"Model file not found\")\n",
    "        return\n",
    "    \n",
    "    os.system(f\"cp {model_file} model.h5\")\n",
    "    os.system(f\"cp {agent_file} main.py\")\n",
    "    os.system(f\"tar cvfz submissions/{sub_name}.tar.gz main.py model.h5\")\n",
    "    os.system(f\"rm main.py\")\n",
    "    os.system(f\"rm model.h5\")\n",
    "    \n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    \n",
    "    api.competition_submit(f\"submissions/{sub_name}.tar.gz\", message,'santa-2020')\n",
    "\n",
    "version='l3_u12_tanh'\n",
    "# submit_model(\"agents/classifier.py\", f\"rl_models/{version}.h5\", f\"classifier_elu_{version}\", f\"RL classifier with ELU activation after {version} iterations\")\n",
    "# submit_model(\"agents/keras.py\", f\"keras_models/{version}.h5\", f\"keras_{version}\", f\"Keras Regressor {version}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = [\n",
    "    lambda n: EnsembleAgent(n, alpha=0.5, keras_file='keras_models/l3_u12_relu.h5', scikit_file='scikit_models/dtr.joblib'),\n",
    "#     lambda n: EnsembleAgent(n, alpha=0.25, keras_file='keras_models/l3_u12_relu.h5', scikit_file='scikit_models/dtr.joblib'),\n",
    "#     lambda n: EnsembleAgent(n, alpha=0.75, keras_file='keras_models/l3_u12_relu.h5', scikit_file='scikit_models/dtr.joblib'),\n",
    "#     lambda n: SklearnAgent(n, filename='scikit_models/random_forest.joblib'),\n",
    "    lambda n: KerasAgent(n, filename='keras_models/l4_u12_relu.h5'),\n",
    "#     lambda n: KerasAgent(n, filename='keras_models/l3_u12_relu.h5'),\n",
    "]\n",
    "\n",
    "simulator.round_robin(agents, num_games=10, min_games=50)\n",
    "# compare_agents(agents, num_games=1)\n",
    "\n",
    "# ranked = rank_agents(agents, num_games=50, min_games=30)\n",
    "\n",
    "# print(\"\\n\")\n",
    "# for a in ranked:\n",
    "#     print(a(100).description())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(agents):\n",
    "    print(f\"P1: {agents[0](100).description()}\")\n",
    "    print(f\"P2: {agents[1](100).description()}\")\n",
    "    _, df = compare_agents(agents, num_games=100, min_games=100)\n",
    "    graph_game_results(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet('training_data/data.parquet')\n",
    "print(f\"\\nLoaded {train_data.shape[0]} training rows\")\n",
    "\n",
    "X = train_data[['step', 'n_pulls', 'n_success', 'n_opp_pulls', 'streak', 'win_streak', 'opp_streak']]\n",
    "y = train_data['threshold']\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sklearn Models\n",
    "\n",
    "Take training data from top-tier games and find a model that predicts actual payout rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val_rmse(regressor, X, y):\n",
    "    cv = -cross_val_score(regressor, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    print(cv)\n",
    "    print(cv.mean())\n",
    "\n",
    "def feature_importance(regressor, X, y):\n",
    "    regressor.fit(X, y)\n",
    "    for name, score in zip(X.columns, regressor.feature_importances_):\n",
    "        print(name, score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "cross_val_rmse(lr, X, y)\n",
    "\n",
    "lr.fit(X, y)\n",
    "joblib.dump(dtr, 'lr_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor(min_samples_leaf=100)\n",
    "# cross_val_rmse(dtr, X, y)\n",
    "# feature_importance(dtr, X, y)\n",
    "dtr.fit(X, y)\n",
    "joblib.dump(dtr, 'scikit_models/dtr.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=100, min_samples_leaf=100, max_depth=10)\n",
    "rfr.fit(X, y)\n",
    "np.sqrt(mean_squared_error(y, rfr.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(max_depth=3, n_estimators=10, learning_rate=0.1)\n",
    "gbr.fit(X, y)\n",
    "joblib.dump(gbr, 'scikit_models/gradient_boosting.joblib')\n",
    "np.sqrt(mean_squared_error(y, gbr.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr_2 = GradientBoostingRegressor(max_depth=3, n_estimators=20, learning_rate=0.1)\n",
    "gbr_2.fit(X, y)\n",
    "np.sqrt(mean_squared_error(y, gbr_2.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr_3 = GradientBoostingRegressor(max_depth=3, n_estimators=30, learning_rate=0.1)\n",
    "gbr_3.fit(X, y)\n",
    "# joblib.dump(gbr_3, 'scikit_models/gradient_boosting_30.joblib')\n",
    "np.sqrt(mean_squared_error(y, gbr_3.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "min_error = 1\n",
    "best = None\n",
    "\n",
    "gbr = GradientBoostingRegressor(max_depth=3, warm_start=True)\n",
    "\n",
    "for i in range(1, 100):\n",
    "    gbr.n_estimators=i\n",
    "    gbr.fit(X, y)\n",
    "    error = np.sqrt(mean_squared_error(y, gbr.predict(X)))\n",
    "    print(f\"n_estimators: {i}, error: {error}\")\n",
    "    \n",
    "    if error < min_error:\n",
    "        best = i\n",
    "        min_error = error\n",
    "        joblib.dump(gbr, 'scikit_models/gradient_boosting_best.joblib')\n",
    "\n",
    "print(\"Best n_estimators:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(gbr_3, 'scikit_models/gradient_boosting_30.joblib')\n",
    "joblib.dump(gbr_2, 'scikit_models/gradient_boosting_20.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr_4 = GradientBoostingRegressor(max_depth=3, n_estimators=40, learning_rate=0.1)\n",
    "gbr_4.fit(X, y)\n",
    "# joblib.dump(gbr, 'scikit_models/gradient_boosting.joblib')\n",
    "np.sqrt(mean_squared_error(y, gbr_4.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(kernel='poly', degree=2, C=10, epsilon=0.5)\n",
    "cross_val_rmse(svr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def create_model(n_hidden_layers=1, \n",
    "                 n_units=10, \n",
    "                 activation='sigmoid', \n",
    "                 hidden_activation='elu',\n",
    "                 input_size=4, \n",
    "                 learning_rate=0.01):\n",
    "    input_layer = Input(shape=(input_size,))\n",
    "\n",
    "    for i in range(n_hidden_layers):\n",
    "        if i == 0:\n",
    "            m = Dense(n_units, activation=hidden_activation)(input_layer)\n",
    "        else:\n",
    "            m = Dense(n_units, activation=hidden_activation)(m)\n",
    "            \n",
    "    m = Dense(1, activation=activation)(m)\n",
    "    \n",
    "    model = Model(inputs=[input_layer], outputs=m)\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# model = create_model()\n",
    "# model.fit(X, y, batch_size=10000, epochs=10, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "Params = namedtuple('Params', ['layers', 'units', 'activation'])\n",
    "\n",
    "params_list = [\n",
    "#     Params(3, 8, 'relu'),\n",
    "#     Params(4, 8, 'relu'),\n",
    "    Params(3, 12, 'selu'),\n",
    "    Params(3, 12, 'elu'),\n",
    "    Params(3, 12, 'tanh'),\n",
    "]\n",
    "\n",
    "files = []\n",
    "\n",
    "for layers, units, activation in params_list:\n",
    "    print(f\"\\nLayers:{layers} Units:{units} Activation:{activation}\")\n",
    "    \n",
    "    model = create_model(n_hidden_layers=layers, \n",
    "                         n_units=units, \n",
    "                         hidden_activation=activation,\n",
    "                         activation='sigmoid', \n",
    "                         input_size=7, \n",
    "                         learning_rate=0.01)\n",
    "\n",
    "    filename = f\"test_models/l{layers}_u{units}_{activation}.h5\"\n",
    "    files.append(filename)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10)\n",
    "    mcp = ModelCheckpoint(filename, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-4)\n",
    "    \n",
    "    model.fit(X, y, batch_size=10000, epochs=100, validation_split=0.05, callbacks=[early_stopping, mcp, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = [\n",
    "    lambda n: KerasAgent(n, filename='test_models/l3_u12_relu.h5'),\n",
    "    lambda n: KerasAgent(n, filename='test_models/l3_u12_selu.h5'),\n",
    "    lambda n: KerasAgent(n, filename='test_models/l3_u12_elu.h5'),\n",
    "    lambda n: KerasAgent(n, filename='test_models/l3_u12_tanh.h5'),\n",
    "]\n",
    "\n",
    "round_robin(agents, num_games=100, min_games=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('keras_models/l3_u8_relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_hidden_layers': [2, 3, 4],\n",
    "    'n_units': [3, 6, 10],\n",
    "    'activation': ['sigmoid'],\n",
    "    'batch_size': [20000]\n",
    "}\n",
    "\n",
    "keras_reg = KerasRegressor(create_model)\n",
    "search_cv = GridSearchCV(keras_reg, params, cv=3)\n",
    "search_cv.fit(X, y, epochs=50, batch_size=20000, callbacks=[EarlyStopping(patience=5)], validation_split=0.05)\n",
    "search_cv.best_params_ # {'activation': 'sigmoid', 'n_hidden_layers': 3, 'n_units': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred_nn = model.predict(X, batch_size=20000)\n",
    "y_pred_dtr = dtr.predict(X)\n",
    "y_pred_dtr = np.reshape(y_pred_dtr, (-1, 1))\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_pred_nn, y)))\n",
    "print(np.sqrt(mean_squared_error(y_pred_dtr, y)))\n",
    "print(np.sqrt(mean_squared_error((y_pred_nn+y_pred_dtr)/2, y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Classifier Model\n",
    "\n",
    "Make a classifier using weights from a regression model and train it using RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create regression model\n",
    "reg_model = create_model(n_hidden_layers=3, n_units=8, activation='sigmoid', input_size=7, learning_rate=0.01)\n",
    "reg_model.summary()\n",
    "\n",
    "reg_model.fit(X, y, batch_size=10000, epochs=100, validation_split=0.05, callbacks=[EarlyStopping(patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# classifier model\n",
    "# takes in a (num_bandits, num_features) array\n",
    "# performs 1D convolutions across the first axis using the regression weights\n",
    "# returns softmax probabilities\n",
    "from tensorflow.keras.layers import Conv1D, Softmax\n",
    "\n",
    "num_bandits = 100\n",
    "num_features = 7\n",
    "num_units = 8 # number of units in regression model hidden layers\n",
    "\n",
    "input_layer = Input(shape=(None, num_features))\n",
    "m = Conv1D(num_units, 1, activation='elu', trainable=False)(input_layer)\n",
    "m = Conv1D(num_units, 1, activation='elu', trainable=False)(m)\n",
    "m = Conv1D(num_units, 1, activation='elu', trainable=False)(m)\n",
    "m = Conv1D(1, 1, activation='sigmoid')(m) # this is the layer trained by RL\n",
    "# m = Softmax(axis=1)(m)\n",
    "\n",
    "clf_model = Model(inputs=[input_layer], outputs=m)\n",
    "opt = Adam(learning_rate=0.01)\n",
    "clf_model.compile(optimizer=opt, loss='categorical_crossentropy')\n",
    "\n",
    "clf_model.summary()\n",
    "\n",
    "for l in clf_model.layers:\n",
    "    print(l.name, l.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set first three Conv1D layers to use regression weights\n",
    "\n",
    "# regression weights need to be reshaped\n",
    "print(\"Layer 1 Classifier weights shape:\", clf_model.layers[1].get_weights()[0].shape)\n",
    "print(\"Layer 1 Regression weights shape:\", reg_model.layers[1].get_weights()[0].shape)\n",
    "\n",
    "for i in range(1, 5):\n",
    "    reg_weights, reg_biases = reg_model.layers[i].get_weights()\n",
    "    clf_shape = clf_model.layers[i].get_weights()[0].shape\n",
    "    reg_weights = np.reshape(reg_weights, clf_shape)\n",
    "    clf_model.layers[i].set_weights([reg_weights, reg_biases])\n",
    "    \n",
    "\n",
    "# clf_model.save('rl_models/latest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fake_data = pd.DataFrame(\n",
    "            index=range(10), \n",
    "            columns=['step', 'n_pulls', 'n_success', 'n_opp_pulls', 'streak', 'win_streak', 'opp_streak']\n",
    "        ).fillna(0)\n",
    "fake_data.iloc[0] = [1, 1, 1, 0, 1, 1, 0]\n",
    "pred = clf_model(np.reshape(fake_data.to_numpy(), (1, -1, 7)))[0]\n",
    "# print(pred.numpy())\n",
    "pred = reg_model(fake_data.to_numpy())\n",
    "# print(pred.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Policy Gradient Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# not sure why only one gradient value is nonzero, fixed by switching to leaky relu\n",
    "# why call tf.reduce_mean if loss is a single value?\n",
    "# convolution works because all classes are interchangeable, and they can share weights\n",
    "# softmax is unnecessary because randomly sampling will be too uniform\n",
    "# dqn not ideal because we know more about the state, and all actions are interchangeable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "epsilon = 0.5 # chance of random action\n",
    "\n",
    "def play_one_step(env, obs, agent, model):\n",
    "    agent.update_states(obs)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tf_probs = model(np.reshape(agent.machine_states.to_numpy(), (1, -1, 7)))\n",
    "        tf_probs = tf.reshape(tf_probs, -1)\n",
    "        probs = tf_probs.numpy()\n",
    "        if random.random() < epsilon:\n",
    "            action = random.randrange(len(probs))\n",
    "        else:\n",
    "            action = int(np.argmax(probs))\n",
    "\n",
    "        y_target = np.zeros(len(probs))\n",
    "        y_target[action] = 1\n",
    "        y_target = tf.constant(y_target)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y_target, tf_probs)\n",
    "    \n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "    return obs, reward, done, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def play_multiple_episodes(env, model, n_episodes):\n",
    "    all_rewards = []\n",
    "    all_grads = []\n",
    "    for episode in range(n_episodes):\n",
    "        current_rewards = []\n",
    "        current_grads = []\n",
    "        agent = ClassifierAgent(100, filename='rl_models/latest.h5')\n",
    "        obs = env.reset()\n",
    "        for step in range(2000):\n",
    "            obs, reward, done, grads = play_one_step(env, obs, agent, model)\n",
    "            current_rewards.append(reward)\n",
    "            current_grads.append(grads)\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        all_rewards.append(current_rewards)\n",
    "        all_grads.append(current_grads)\n",
    "    return all_rewards, all_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_factor):\n",
    "    discounted = np.array(rewards)\n",
    "    for step in range(len(rewards) - 2, -1, -1):\n",
    "        discounted[step] += discount_factor * discounted[step+1] \n",
    "    \n",
    "    return discounted\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_factor):\n",
    "    all_discounted_rewards = [discount_rewards(r, discount_factor) for r in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = np.mean(flat_rewards)\n",
    "    reward_std = np.std(flat_rewards)\n",
    "    \n",
    "    return [(r - reward_mean) / reward_std for r in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rewards = [[0, 1, 5, 10, 3], [-10, 5, -20, 5]]\n",
    "\n",
    "print(discount_rewards(rewards[0], 0.97))\n",
    "print(discount_rewards(rewards[1], 0.97))\n",
    "print(discount_and_normalize_rewards(rewards, 0.97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kaggle_environments import make\n",
    "\n",
    "discount_factor = 0.97\n",
    "n_episodes_per_update = 3\n",
    "start_iteration = 1\n",
    "num_iterations = 50\n",
    "starting_model = 'rl_models/latest.h5'\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "opponents = [\n",
    "#     lambda n: EnsembleAgent(n, alpha=0.5, keras_file='keras_models/l3_u8_relu.h5', scikit_file='scikit_models/dtr.joblib'),\n",
    "    lambda n: PullVegasAgent(n),\n",
    "    lambda n: ClassifierAgent(n, filename='rl_models/latest.h5')\n",
    "]\n",
    "\n",
    "opponent = None\n",
    "def opp_step(obs, config):\n",
    "    global opponent\n",
    "    if obs.step == 0:\n",
    "        opponent = random.choice(opponents)(100)\n",
    "    return opponent.step(obs, config)\n",
    "\n",
    "env = make(\"mab\", debug=True)\n",
    "trainer = env.train([None, opp_step])\n",
    "\n",
    "model = keras.models.load_model(starting_model)\n",
    "# for l in model.layers:\n",
    "#     l.trainable = True\n",
    "\n",
    "for i in tqdm(range(start_iteration, start_iteration+num_iterations)):\n",
    "    all_rewards, all_grads = play_multiple_episodes(trainer, model, n_episodes_per_update)\n",
    "    all_final_rewards = discount_and_normalize_rewards(all_rewards, discount_factor) \n",
    "    all_mean_grads = []\n",
    "\n",
    "    for var_index in range(len(model.trainable_variables)):\n",
    "        var_grads = []\n",
    "        for episode_index, final_rewards in enumerate(all_final_rewards):\n",
    "            for step, final_reward in enumerate(final_rewards):\n",
    "                grad = all_grads[episode_index][step][var_index]\n",
    "                var_grads.append(final_reward * grad)\n",
    "\n",
    "        mean_grads = tf.reduce_mean(var_grads, axis=0)\n",
    "        all_mean_grads.append(mean_grads)\n",
    "\n",
    "    optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))\n",
    "    model.save(f\"rl_models/{i}.h5\")\n",
    "    model.save(f\"rl_models/latest.h5\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "agents = [\n",
    "#     lambda n: EnsembleAgent(n, alpha=0.5, keras_file='keras_models/l3_u8_relu.h5', scikit_file='scikit_models/dtr.joblib'),\n",
    "#     lambda n: ClassifierAgent(n, filename='rl_models/130.h5'),\n",
    "#     lambda n: KerasAgent(n, filename='keras_models/l3_u8_relu.h5'),\n",
    "    lambda n: ClassifierAgent(n, filename='rl_models/latest.h5'),\n",
    "    lambda n: ClassifierAgent(n, filename='rl_models/0.h5'),\n",
    "#     lambda n: ClassifierAgent(n, filename='rl_models/relu/21.h5'),\n",
    "#     lambda n: UcbAgent(),\n",
    "#     lambda n: PullVegasAgent(100),\n",
    "]\n",
    "\n",
    "round_robin(agents, num_games=100, min_games=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing in Kaggle Environment\n",
    "Not ideal for performance testing, but double-checks that they'll work online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "env = make(\"mab\", debug=True)\n",
    "\n",
    "env.reset()\n",
    "env.run([ \"decision_tree.py\", \"keras_agent.py\"])\n",
    "print(env)\n",
    "env.render(mode=\"ipython\", width=800, height=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "@ray.remote\n",
    "def run_trial():\n",
    "    env = make(\"mab\")\n",
    "    env.reset()\n",
    "    env.run([\"bayesian_ucb_with_02_opp_and_rand.py\", \"decision_tree.py\"])\n",
    "    return env.state\n",
    "\n",
    "result_ids = [run_trial.remote() for i in range(10)]\n",
    "\n",
    "results = ray.get(result_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from kaggle_environments import evaluate\n",
    "\n",
    "results = np.array(evaluate(\"mab\", [\"keras_agent.py\", \"decision_tree.py\"], num_episodes=1))\n",
    "print_stats(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make(\"mab\", debug=True)\n",
    "agent = SklearnAgent(100, filename='scikit_models/dtr.joblib')\n",
    "env.run([lambda o,c: agent.step(o, c), \"random\"])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
